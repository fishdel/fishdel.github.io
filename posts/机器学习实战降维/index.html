<!DOCTYPE html>
<html lang="zh" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>机器学习实战(降维) | Yuuuuu&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="降维
主要动机
加速，可视化数据，节省空间
缺点：丢失信息，计算密集，转换过程难以理解
什么时候用到降维
分类前，加速；聚类前，可视化数据
维度诅咒
高维数据集——非常稀疏——训练实例彼此远离——容易过拟合">
<meta name="author" content="">
<link rel="canonical" href="https://fishdel.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E9%99%8D%E7%BB%B4/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css" integrity="sha256-1vzSCk&#43;4bvpN&#43;sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://fishdel.github.io/favicon.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://fishdel.github.io/favicon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://fishdel.github.io/favicon.png">
<link rel="apple-touch-icon" href="https://fishdel.github.io/favicon.png">
<link rel="mask-icon" href="https://fishdel.github.io/favicon.png">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh" href="https://fishdel.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E9%99%8D%E7%BB%B4/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://fishdel.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E9%99%8D%E7%BB%B4/">
  <meta property="og:site_name" content="Yuuuuu&#39;s Blog">
  <meta property="og:title" content="机器学习实战(降维)">
  <meta property="og:description" content="降维 主要动机 加速，可视化数据，节省空间
缺点：丢失信息，计算密集，转换过程难以理解
什么时候用到降维 分类前，加速；聚类前，可视化数据
维度诅咒 高维数据集——非常稀疏——训练实例彼此远离——容易过拟合">
  <meta property="og:locale" content="zh">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2022-04-05T22:11:08+08:00">
    <meta property="article:modified_time" content="2022-04-05T22:11:08+08:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习实战(降维)">
<meta name="twitter:description" content="降维
主要动机
加速，可视化数据，节省空间
缺点：丢失信息，计算密集，转换过程难以理解
什么时候用到降维
分类前，加速；聚类前，可视化数据
维度诅咒
高维数据集——非常稀疏——训练实例彼此远离——容易过拟合">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://fishdel.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "机器学习实战(降维)",
      "item": "https://fishdel.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E9%99%8D%E7%BB%B4/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "机器学习实战(降维)",
  "name": "机器学习实战(降维)",
  "description": "降维 主要动机 加速，可视化数据，节省空间\n缺点：丢失信息，计算密集，转换过程难以理解\n什么时候用到降维 分类前，加速；聚类前，可视化数据\n维度诅咒 高维数据集——非常稀疏——训练实例彼此远离——容易过拟合\n",
  "keywords": [
    
  ],
  "articleBody": "降维 主要动机 加速，可视化数据，节省空间\n缺点：丢失信息，计算密集，转换过程难以理解\n什么时候用到降维 分类前，加速；聚类前，可视化数据\n维度诅咒 高维数据集——非常稀疏——训练实例彼此远离——容易过拟合\n主要动机：特征过多，训练变得缓慢，难以寻找更好的解决方案\n例子：MNIST数据集中图像边界的像素全是白色，删除这些像素也不会丢失太多信息，或者相邻两个像素合并。\n降维的主要方法 投影：适用于一个分布接近于2D子空间的3D数据集\n流形学习：瑞士卷数据集\n投影 投影的方法：PCA （主成分分析）寻找训练集中可获得最大方差的轴。\n如何寻找训练集的主成分 奇异值分解（SVD）\n使用numpy提供的svd（）函数获得训练集的主成分 如果不是用sklearn的PCA类，就要将数据集做中心化处理.\nX_centered=X-X.mean(axis=0)` `U,s,V=np.linalg.svd(X_centered)` `c1=V.T[:,0]` `c2=V.T[:,1] 有了奇异值分解得到的V，任意选取前d个主成分点乘原始数据集便可实现在d维的投影。\nW2 = V.T[:,:2]` `X2D=X_centered.dot(W2) sklearn实现PCA from sklearn.decomposition import PCA` `pca=PCA(n_components=2)` `X2D=pca.fit_transform(X) 使用components_访问每一个主成分\n`pca.components_.T[:,0]` 方差解释率 pca.explained_variance_ratio_` `pca = PCA(n_components=0.95) 可以将 n_components 设置为 0.0 到 1.0 之间的浮点数，表明希望保留的方差比率 cumsum = np.cumsum(pca.explained_variance_ratio_)` `d = np.argmax(cumsum \u003e= 0.95)+1 也可以保留相加足够大的方差部分维度\n也可以画图寻找拐点\nplt.plot(cumsum,linewidth=3)\nQ：假设你对一个 1000 维的数据集应用 PCA，同时设置方差解释率为 95%，你的最终数据集将会有多少维？\n可能是1-1000之间的任何数字，取决于数据集，\nPCA数据压缩 `pca = PCA(n_components=154)` `X_reduced = pca.fit_transform(X_train)` `X_recovered = pca.inverse_transform(X_reduced)` 几种不同的PCA 随机PCA `rnd_pca = PCA(n_components=154,svd_solver='randomized',random_state=42)` `X_reduced = rnd_pca.fit_transform(X_train)` 增量PCA：对于大型数据集可以划分成小批量，但是要在每个小批量里调用partial_fit方法 from sklearn.decomposition import IncrementalPCA` `n_batches = 100` `inc_pca = IncrementalPCA(n_components=154)` `for X_batch in np.array_split(X_train,n_batches):` `inc_pca.partial_fit(X_batch)` `X_reduced = inc_pca.transform(X_train)` Kernel PCA `from sklearn.decomposition import KernelPCA rbf_pca=KernelPCA(n_components=2,kernel='rbf',gamma=0.04) X_reduced=rbf_pca.fit_transform(X)` 为kPCA调参方法 引入模型，通过最优化模型表现调参\n`from sklearn.model_selection import GridSearchCV` `from sklearn.linear_model import LogisticRegression` `from sklearn.pipeline import Pipeline` `clf = Pipeline([` `(\"kpca\",KernelPCA(n_components=2)),` `(\"log_reg\",LogisticRegression(solver=\"lbfgs\"))` `])` `param_grid = [{` `\"kpca__gamma\":np.linspace(0.03,0.05,10), \"kpca__kernel\":[\"rbf\",\"sigmoid\"]` `}]` `grid_search = GridSearchCV(clf,param_grid,cv=3)` `grid_search.fit(X,y)` 2.基于重建功能算误差\n`best_score = 0.0` `for gamma in np.linspace(0.01, 0.05, 10):` `for kernel in [\"rbf\", \"sigmoid\"]:` `kpca = KernelPCA(n_components=27,fit_inverse_transform=True)` `X_reduced = kpca.fit_transform(X)` `X_preimage = kpca.inverse_transform(X_reduced )` score = mean_squared_error(X, X_preimage) if score \u003e best_score: best_score = score best_parameters = {'gamma':gamma,'kernel':kernel} print(best_parameters,best_score) 各种PCA的选择 首选常规PCA，不适合内存的大型数据集用增量PCA，想要大幅度降低维度并且追求速度用随机PCA，非线性数据集用内核PCA\n流形学习 LLE from sklearn.manifold import LocallyLinearEmbedding lle=LocallyLinearEmbedding(n_components=2,n_neighbors=10) X_reduced=lle.fit_transform(X) ",
  "wordCount" : "851",
  "inLanguage": "zh",
  "datePublished": "2022-04-05T22:11:08+08:00",
  "dateModified": "2022-04-05T22:11:08+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://fishdel.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E9%99%8D%E7%BB%B4/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Yuuuuu's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://fishdel.github.io/favicon.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://fishdel.github.io/" accesskey="h" title="Yuuuuu&#39;s Blog (Alt + H)">Yuuuuu&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://fishdel.github.io/" title="首页">
                    <span>首页</span>
                </a>
            </li>
            <li>
                <a href="https://fishdel.github.io/archives/" title="归档">
                    <span>归档</span>
                </a>
            </li>
            <li>
                <a href="https://fishdel.github.io/categories/" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="https://fishdel.github.io/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="https://fishdel.github.io/search/" title="搜索">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="https://fishdel.github.io/about/" title="关于">
                    <span>关于</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      机器学习实战(降维)
    </h1>
    <div class="post-meta"><span title='2022-04-05 22:11:08 +0800 CST'>四月 5, 2022</span>

</div>
  </header> 
  <div class="post-content"><h2 id="降维">降维<a hidden class="anchor" aria-hidden="true" href="#降维">#</a></h2>
<h3 id="主要动机">主要动机<a hidden class="anchor" aria-hidden="true" href="#主要动机">#</a></h3>
<p>加速，可视化数据，节省空间</p>
<p>缺点：丢失信息，计算密集，转换过程难以理解</p>
<h3 id="什么时候用到降维">什么时候用到降维<a hidden class="anchor" aria-hidden="true" href="#什么时候用到降维">#</a></h3>
<p>分类前，加速；聚类前，可视化数据</p>
<h3 id="维度诅咒">维度诅咒<a hidden class="anchor" aria-hidden="true" href="#维度诅咒">#</a></h3>
<p>高维数据集——非常稀疏——训练实例彼此远离——容易过拟合</p>
<p>主要动机：特征过多，训练变得缓慢，难以寻找更好的解决方案</p>
<p>例子：MNIST数据集中图像边界的像素全是白色，删除这些像素也不会丢失太多信息，或者相邻两个像素合并。</p>
<h3 id="降维的主要方法">降维的主要方法<a hidden class="anchor" aria-hidden="true" href="#降维的主要方法">#</a></h3>
<p>投影：适用于一个分布接近于2D子空间的3D数据集</p>
<p>流形学习：瑞士卷数据集</p>
<h3 id="投影">投影<a hidden class="anchor" aria-hidden="true" href="#投影">#</a></h3>
<p>投影的方法：PCA （主成分分析）寻找训练集中可获得最大方差的轴。</p>
<h5 id="如何寻找训练集的主成分">如何寻找训练集的主成分<a hidden class="anchor" aria-hidden="true" href="#如何寻找训练集的主成分">#</a></h5>
<p>奇异值分解（SVD）</p>
<h5 id="使用numpy提供的svd函数获得训练集的主成分">使用numpy提供的svd（）函数获得训练集的主成分<a hidden class="anchor" aria-hidden="true" href="#使用numpy提供的svd函数获得训练集的主成分">#</a></h5>
<p>如果不是用sklearn的PCA类，就要将数据集做中心化处理.</p>
<pre tabindex="0"><code>X_centered=X-X.mean(axis=0)`

`U,s,V=np.linalg.svd(X_centered)`

`c1=V.T[:,0]`

`c2=V.T[:,1]
</code></pre><p>有了奇异值分解得到的V，任意选取前d个主成分点乘原始数据集便可实现在d维的投影。</p>
<pre tabindex="0"><code>W2 = V.T[:,:2]`

`X2D=X_centered.dot(W2)
</code></pre><h5 id="sklearn实现pca">sklearn实现PCA<a hidden class="anchor" aria-hidden="true" href="#sklearn实现pca">#</a></h5>
<pre tabindex="0"><code>from sklearn.decomposition import PCA` 

`pca=PCA(n_components=2)`

 `X2D=pca.fit_transform(X)
</code></pre><p>使用components_访问每一个主成分</p>
<pre tabindex="0"><code>`pca.components_.T[:,0]`
</code></pre><h5 id="方差解释率">方差解释率<a hidden class="anchor" aria-hidden="true" href="#方差解释率">#</a></h5>
<pre tabindex="0"><code>pca.explained_variance_ratio_`

`pca = PCA(n_components=0.95)
</code></pre><ul>
<li>可以将 n_components 设置为 0.0 到 1.0 之间的浮点数，表明希望保留的方差比率</li>
</ul>
<pre tabindex="0"><code>cumsum = np.cumsum(pca.explained_variance_ratio_)`

`d = np.argmax(cumsum &gt;= 0.95)+1
</code></pre><ul>
<li>
<p>也可以保留相加足够大的方差部分维度</p>
</li>
<li>
<p>也可以画图寻找拐点</p>
<p><code>plt.plot(cumsum,linewidth=3)</code></p>
<p>Q：假设你对一个 1000 维的数据集应用 PCA，同时设置方差解释率为 95%，你的最终数据集将会有多少维？</p>
<p>可能是1-1000之间的任何数字，取决于数据集，</p>
</li>
</ul>
<h5 id="pca数据压缩">PCA数据压缩<a hidden class="anchor" aria-hidden="true" href="#pca数据压缩">#</a></h5>
<pre tabindex="0"><code>`pca = PCA(n_components=154)`
`X_reduced = pca.fit_transform(X_train)`
`X_recovered = pca.inverse_transform(X_reduced)`
</code></pre><h5 id="几种不同的pca">几种不同的PCA<a hidden class="anchor" aria-hidden="true" href="#几种不同的pca">#</a></h5>
<ul>
<li>随机PCA</li>
</ul>
<pre tabindex="0"><code>`rnd_pca = PCA(n_components=154,svd_solver=&#39;randomized&#39;,random_state=42)`
`X_reduced = rnd_pca.fit_transform(X_train)`
</code></pre><ul>
<li>增量PCA：对于大型数据集可以划分成小批量，但是要在每个小批量里调用partial_fit方法</li>
</ul>
<pre tabindex="0"><code>from sklearn.decomposition import IncrementalPCA`

`n_batches = 100`
`inc_pca = IncrementalPCA(n_components=154)`
`for X_batch in np.array_split(X_train,n_batches):`
    `inc_pca.partial_fit(X_batch)`

`X_reduced = inc_pca.transform(X_train)`    
</code></pre><ul>
<li>Kernel PCA</li>
</ul>
<pre tabindex="0"><code>`from sklearn.decomposition import KernelPCA rbf_pca=KernelPCA(n_components=2,kernel=&#39;rbf&#39;,gamma=0.04) X_reduced=rbf_pca.fit_transform(X)`
</code></pre><ul>
<li>为kPCA调参方法</li>
</ul>
<ol>
<li>
<p>引入模型，通过最优化模型表现调参</p>
<pre tabindex="0"><code>`from sklearn.model_selection import GridSearchCV`
`from sklearn.linear_model import LogisticRegression`
`from sklearn.pipeline import Pipeline`

`clf = Pipeline([`
    `(&#34;kpca&#34;,KernelPCA(n_components=2)),`
    `(&#34;log_reg&#34;,LogisticRegression(solver=&#34;lbfgs&#34;))`
`])`

`param_grid = [{`
    `&#34;kpca__gamma&#34;:np.linspace(0.03,0.05,10),
    &#34;kpca__kernel&#34;:[&#34;rbf&#34;,&#34;sigmoid&#34;]`
`}]`

`grid_search = GridSearchCV(clf,param_grid,cv=3)`
`grid_search.fit(X,y)`
</code></pre></li>
</ol>
<p>2.基于重建功能算误差</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="err">`</span><span class="n">best_score</span> <span class="o">=</span> <span class="mf">0.0</span><span class="err">`</span>
</span></span><span class="line"><span class="cl"><span class="err">`</span><span class="k">for</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span><span class="err">`</span>
</span></span><span class="line"><span class="cl">    <span class="err">`</span><span class="k">for</span> <span class="n">kernel</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&#34;rbf&#34;</span><span class="p">,</span> <span class="s2">&#34;sigmoid&#34;</span><span class="p">]:</span><span class="err">`</span>
</span></span><span class="line"><span class="cl">        <span class="err">`</span><span class="n">kpca</span> <span class="o">=</span> <span class="n">KernelPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">27</span><span class="p">,</span><span class="n">fit_inverse_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="err">`</span>
</span></span><span class="line"><span class="cl">        <span class="err">`</span><span class="n">X_reduced</span> <span class="o">=</span> <span class="n">kpca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="err">`</span>
</span></span><span class="line"><span class="cl">        <span class="err">`</span><span class="n">X_preimage</span> <span class="o">=</span> <span class="n">kpca</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">X_reduced</span> <span class="p">)</span><span class="err">`</span>
</span></span><span class="line"><span class="cl">         <span class="n">score</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X_preimage</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">best_score</span> <span class="o">=</span> <span class="n">score</span>
</span></span><span class="line"><span class="cl">            <span class="n">best_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;gamma&#39;</span><span class="p">:</span><span class="n">gamma</span><span class="p">,</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span><span class="n">kernel</span><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">best_parameters</span><span class="p">,</span><span class="n">best_score</span><span class="p">)</span>
</span></span></code></pre></div><h4 id="各种pca的选择">各种PCA的选择<a hidden class="anchor" aria-hidden="true" href="#各种pca的选择">#</a></h4>
<p>首选常规PCA，不适合内存的大型数据集用增量PCA，想要大幅度降低维度并且追求速度用随机PCA，非线性数据集用内核PCA</p>
<h3 id="流形学习">流形学习<a hidden class="anchor" aria-hidden="true" href="#流形学习">#</a></h3>
<h5 id="lle">LLE<a hidden class="anchor" aria-hidden="true" href="#lle">#</a></h5>
<pre tabindex="0"><code>from sklearn.manifold import LocallyLinearEmbedding
lle=LocallyLinearEmbedding(n_components=2,n_neighbors=10)
X_reduced=lle.fit_transform(X)
</code></pre>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span><a href="https://fishdel.github.io/">©2024 Yuuuu&rsquo;s Blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
